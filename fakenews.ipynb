{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4yEhkjFhbqJ"
   },
   "outputs": [],
   "source": [
    "# Install kagglehub\n",
    "!pip install kagglehub -q\n",
    "\n",
    "# Set Kaggle credentials (replace with your own Kaggle username & API key)\n",
    "# Uncomment below segment and add your own kaggle username and key\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"\"\n",
    "os.environ['KAGGLE_KEY'] = \"\"\n",
    "\"\"\"\n",
    "\n",
    "# Import kagglehub and download WELFake dataset\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = kagglehub.dataset_download(\"vcclab/welfake-dataset\")\n",
    "print(\"Dataset downloaded to:\", path)\n",
    "\n",
    "# Load CSV into pandas\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "print(\"CSV files found:\", csv_files)\n",
    "\n",
    "df = pd.read_csv(csv_files[0])\n",
    "print(\"Dataframe shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# Download all required NLTK resources (including the 'eng' variant)\n",
    "for resource in ['punkt', 'punkt_tab', 'wordnet', 'omw-1.4',\n",
    "                 'averaged_perceptron_tagger', 'averaged_perceptron_tagger_eng',\n",
    "                 'stopwords']:\n",
    "    nltk.download(resource, quiet=True)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Step 0: Shuffle the dataset\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# 1. Remove unnecessary columns safely\n",
    "df = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "# 2. Handle missing data\n",
    "df = df.dropna(subset=['title', 'text'])\n",
    "\n",
    "# 3. Combine text features\n",
    "df['content'] = df['title'] + \" \" + df['text']\n",
    "\n",
    "# 4. Text cleaning: lowercase and strip spaces\n",
    "df['content'] = df['content'].str.lower().str.strip()\n",
    "\n",
    "# 5. Remove punctuation\n",
    "df['content'] = df['content'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "# 6. POS-aware lemmatization with stopword removal\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    \"\"\"Map NLTK POS tags to WordNet POS tags for lemmatization.\"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Tokenize, remove stopwords, POS-aware lemmatize, and return cleaned string.\"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word, get_wordnet_pos(pos))\n",
    "             for word, pos in pos_tag(words)\n",
    "             if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['content'] = df['content'].apply(preprocess_text)\n",
    "\n",
    "print(\"Preprocessing done. Dataset shape:\", df.shape)\n",
    "print(df.head())\n"
   ],
   "metadata": {
    "id": "Jdul7rTVhqti"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Label distribution (bar plot)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='label', data=df, palette=\"viridis\")\n",
    "plt.title(\"Label Distribution (0 = real, 1 = fake)\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Text length distribution (histogram)\n",
    "df['text_length'] = df['content'].apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['text_length'], bins=50, kde=True, color='skyblue')\n",
    "plt.title(\"Text Length Distribution\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Word count boxplot (to see outliers)\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='text_length', data=df, color='lightgreen')\n",
    "plt.title(\"Boxplot of Text Length\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Top 15 most frequent words (bar plot)\n",
    "all_words = ' '.join(df['content']).split()\n",
    "word_counts = Counter(all_words)\n",
    "top_words = dict(word_counts.most_common(15))\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=list(top_words.values()), y=list(top_words.keys()), palette=\"magma\")\n",
    "plt.title(\"Top 15 Most Frequent Words\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Words\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Article length vs label (violin plot)\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.violinplot(x='label', y='text_length', data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Text Length Distribution by Label\")\n",
    "plt.xlabel(\"Label (0=real, 1=fake)\")\n",
    "plt.ylabel(\"Number of Words\")\n",
    "plt.show()\n",
    "\n",
    "# 6. Label proportion pie chart\n",
    "label_counts = df['label'].value_counts()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(label_counts, labels=['Fake','Real'], autopct='%1.1f%%', colors=['tomato','lightblue'], startangle=140)\n",
    "plt.title(\"Proportion of Fake vs Real News\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 7. Wordcloud\n",
    "# Separate real and fake news\n",
    "real_text = \" \".join(df[df['label'] == 0]['content'])\n",
    "fake_text = \" \".join(df[df['label'] == 1]['content'])\n",
    "\n",
    "# Generate word clouds\n",
    "real_wc = WordCloud(width=800, height=400, background_color='white', max_words=200).generate(real_text)\n",
    "fake_wc = WordCloud(width=800, height=400, background_color='white', max_words=200).generate(fake_text)\n",
    "\n",
    "# Plot word clouds\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(real_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Real News Word Cloud', fontsize=20)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(fake_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Fake News Word Cloud', fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "CfnsvLSchu9G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Define features (X) and target (y)\n",
    "X = df['content']\n",
    "y = df['label']\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # stratify is good for classification\n",
    "\n",
    "# 3. Initialize and fit the vectorizer ONLY on the training data\n",
    "print(\"Fitting TF-IDF Vectorizer on training data...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# 4. Transform the test data using the already-fitted vectorizer\n",
    "print(\"Transforming test data...\")\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Data is ready for model training.\")"
   ],
   "metadata": {
    "id": "kqRCV9A8MRms"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Define the model i want to tune\n",
    "log_reg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 2. Set up the grid of parameters to test\n",
    "# This grid will create 3 (C values) * 2 (solvers) = 6 different model 'varieties' to test.\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Controls regularization. Lower values prevent overfitting.\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# 3. Configuring the grid search\n",
    "# cv=5 means 5-fold cross-validation\n",
    "# scoring='f1' tells it to find the model with the best F1-score\n",
    "grid_search = GridSearchCV(estimator=log_reg_model, param_grid=param_grid, cv=5, scoring='f1', verbose=2, n_jobs=-1)\n",
    "\n",
    "# 4. Run the tuning process on your training data\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 5. Extract the best model found\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "print(f\"\\\\nBest Hyperparameters Found: {grid_search.best_params_}\")\n",
    "print(f\"Best F1-score from cross-validation: {grid_search.best_score_:.4f}\")"
   ],
   "metadata": {
    "id": "RQ3K-vP8MVtO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions on the unseen test data\n",
    "y_pred = best_lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Print the detailed classification report\n",
    "print(\"\\\\nFinal modeleval report :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Real', 'Fake']))\n",
    "\n",
    "# Visualize the Confusion Matrix\n",
    "print(\"confution matrix :\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "_m15QYCcMYUe"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
